{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c7d1256",
   "metadata": {},
   "source": [
    "# Halvor -- problem d\n",
    "## Cross-validation as resampling techniques, adding more complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0097686",
   "metadata": {},
   "source": [
    "## Why resampling methods:\n",
    "Before we proceed, we need to rethink what we have been doing. In our eager to fit the data, we have omitted several important elements in our regression analysis. In what follows we will\n",
    "\n",
    "1.look at statistical properties, including a discussion of mean values, variance and the so-called bias-variance tradeoff\n",
    "\n",
    "2.introduce resampling techniques like cross-validation, bootstrapping and jackknife and more\n",
    "and discuss how to select a given model (one of the difficult parts in machine learning).\n",
    "\n",
    "Resampling methods are an indispensable tool in modern statistics. They involve repeatedly drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about the fitted model. For example, in order to estimate the variability of a linear regression fit, we can repeatedly draw different samples from the training data, fit a linear regression to each new sample, and then examine the extent to which the resulting fits differ. Such an approach may allow us to obtain information that would not be available from fitting the model only once using the original training sample\n",
    "\n",
    "Our simulations can be treated as computer experiments. This is particularly the case for Monte Carlo methods which are widely used in statistical analyses.\n",
    "\n",
    "The results can be analysed with the same statistical tools as we would use when analysing experimental data.\n",
    "\n",
    "As in all experiments, we are looking for expectation values and an estimate of how accurate they are, i.e., possible sources for errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57498f",
   "metadata": {},
   "source": [
    "### two resampeling methods:\n",
    "a.bootstrap - problem c)\n",
    "\n",
    "b.cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d834f",
   "metadata": {},
   "source": [
    "# Cross validation:\n",
    "\n",
    "cross-validation can be used to estimate the test error associated with a given statistical learning method in order to evaluate its performance, or to select the appropriate level of flexibility. The process of evaluating a model’s performance is known as model assessment, whereas the process of selecting the proper level of flexibility for a model is known as model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1cb6f5",
   "metadata": {},
   "source": [
    "## Various steps in cross-validation\n",
    "\n",
    "When the repetitive splitting of the data set is done randomly, samples may accidently end up in a fast majority of the splits in either training or test set. Such samples may have an unbalanced influence on either model building or prediction evaluation. \n",
    "\n",
    "To avoid this k-fold cross-validation structures the data splitting. \n",
    "The samples are divided into k, more or less equally sized exhaustive and mutually exclusive subsets. In turn (at each split) one of these subsets plays the role of the test set while the union of the remaining subsets constitutes the training set. \n",
    "\n",
    "Such a splitting warrants a balanced representation of each sample in both training and test set over the splits. Still the division into the k subsets involves a degree of randomness. \n",
    "\n",
    "This may be fully excluded when choosing k=n. This particular case is referred to as leave-one-out cross-validation (LOOCV)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0f2cd6",
   "metadata": {},
   "source": [
    "### Cross-validation in brief\n",
    "For the various values of k\n",
    "\n",
    "1.shuffle the dataset randomly.\n",
    "\n",
    "2.Split the dataset into k groups.\n",
    "\n",
    "3.For each unique group:\n",
    "\n",
    "    a.Decide which group to use as set for test data\n",
    "    \n",
    "    b.Take the remaining groups as a training data set\n",
    "    \n",
    "    c.Fit a model on the training set and evaluate it on the test set\n",
    "    \n",
    "    d.Retain the evaluation score and discard the model\n",
    "    \n",
    "4.Summarize the model using the sample of model evaluation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b923f5",
   "metadata": {},
   "source": [
    "# Problem text:\n",
    "--------------------------\n",
    "The aim here is to write your own code for another widely popular resampling technique, the so-called cross-validation method. Again, before you start with cross-validation approach, you should scale your data if you think this is needed.\n",
    "\n",
    "Implement the k\n",
    "-fold cross-validation algorithm (write your own code) and evaluate again the MSE function resulting from the test folds. You can compare your own code with that from Scikit-Learn if needed.\n",
    "\n",
    "Compare the MSE you get from your cross-validation code with the one you got from your bootstrap code. Comment your results. Try 5−10\n",
    " folds. You can also compare your own cross-validation code with the one provided by Scikit-Learn.\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26298562",
   "metadata": {},
   "source": [
    "# Problem Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "353eda49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "4cc9cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from reggresion_tools:\n",
    "def create_X_polynomial(x, y, n):\n",
    "    if len(x.shape) > 1:\n",
    "        x = np.ravel(x)\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    N = len(x)\n",
    "    l = int((n+1)*(n+2)/2)      # Number of elements in beta\n",
    "    X = np.ones((N,l))\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        q = int((i)*(i+1)/2)\n",
    "        for k in range(i+1):\n",
    "            X[:,q+k] = (x**(i-k))*(y**k)\n",
    "\n",
    "    return X\n",
    "\n",
    "def linreg_polynomial(x, y, z, n):\n",
    "    X = create_X_polynomial(x, y, n)\n",
    "\n",
    "    # Solving for beta\n",
    "    beta = np.linalg.inv(X.T @ X) @ X.T @ z\n",
    "    return beta\n",
    "\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d56ff3",
   "metadata": {},
   "source": [
    "## model Ridge and Lasso implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "1967ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression\n",
    "def ridgereg_polynomial(x, y, z, degree, lambdan):\n",
    "    #design matrix\n",
    "    X = create_X_polynomial(x, y, degree)\n",
    "    #create identity matrix\n",
    "    I = np.eye(len(X.T), len(X.T))\n",
    "    \n",
    "    # Solving for beta\n",
    "    beta_ridge = np.linalg.pinv(X.T@X + lambdan*I) @ X.T @ z\n",
    "    return beta_ridge\n",
    "\n",
    "#Lassso mit scikit-learn:\n",
    "def lassoreg_polynomial(x, y, z, degree, lambdan):\n",
    "    #design matrix\n",
    "    X = create_X_polynomial(x, y, degree)\n",
    "    \n",
    "    #Lasso regression with scikit-learn \n",
    "    RegLasso = Lasso(lambdan)\n",
    "    RegLasso.fit(X,z)\n",
    "    beta_lasso = RegLasso.coef_\n",
    "    return beta_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "befd5034",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(244) #The same as in task b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "fd1064cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#franke fuction from task b)\n",
    "def FrankeFunction(x,y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "596a01db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating datapoints\n",
    "x = np.np.random.random(40)) # + (1/5) * np.random.normal(0, 1, 25))\n",
    "y = np.sort(np.random.random(40))\n",
    "z = FrankeFunction(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "526313b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(k_deg_fold, x, y, z, model_fit=linreg_polynomial, degree=2, lambdan=0):\n",
    "    #step 1: shuffle datasets randomly using np.random.permutation(len(x)):\n",
    "    assert len(x) == len(z) == len(y)\n",
    "    p = np.random.permutation(len(x))\n",
    "    x, y, z = x[p], y[p], z[p]\n",
    "    \n",
    "    #step 2: split the data in k groups with numpy.array_split\n",
    "    x = np.array_split(x, k_deg_fold); \n",
    "    y = np.array_split(y, k_deg_fold); \n",
    "    z = np.array_split(z, k_deg_fold)\n",
    "\n",
    "    # array to keep track of MSE for each test-group\n",
    "    MSE_array = np.zeros((k_deg_fold))\n",
    "    \n",
    "    #step 3:\n",
    "    for i in range(k_deg_fold):\n",
    "        #a) pick one group to be test data\n",
    "        x_test, y_test, z_test = x[i], y[i], z[i]\n",
    "        \n",
    "        #b) take remaining groupe as train data\n",
    "        x_train = np.ndarray.flatten(np.array(x[:i] + x[i+1:]))\n",
    "        y_train = np.ndarray.flatten(np.array(y[:i] + y[i+1:]))\n",
    "        z_train = np.ndarray.flatten(np.array(z[:i] + z[i+1:]))\n",
    "        \n",
    "        #X_train = create_X_polynomial(x_train, y_train, 2)\n",
    "        \n",
    "        #c) fit model to train data\n",
    "        if model_fit == linreg_polynomial:\n",
    "            beta = model_fit(x_train, y_train, z_train, degree)\n",
    "        elif model_fit == ridgereg_polynomial or model_fit == lassoreg_polynomial:\n",
    "            beta = model_fit(x_train, y_train, z_train, degree, lambdan)\n",
    "        \n",
    "        #d) evaluate model and save score-value\n",
    "        X_test = create_X_polynomial(x_test, y_test, degree)\n",
    "        z_tilde = X_test @ beta \n",
    "        MSE_array[i] = MSE(z_test, z_tilde)\n",
    "        \n",
    "    return MSE_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "43b739db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00346698, 0.01052689, 0.01128705, 0.03093545, 0.00602354,\n",
       "       0.00240833, 0.00749399, 0.00863021, 0.00134337, 0.00507218])"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(244)\n",
    "cross_validation(10, x, y, z, model_fit=linreg_polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "c3e2fd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0102417 , 0.0064399 , 0.02432365, 0.00538653, 0.00500456,\n",
       "       0.01907118, 0.003358  , 0.00522926, 0.01152256, 0.07964081])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(10, x, y, z, model_fit=ridgereg_polynomial, lambdan=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "33067306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19462191, 0.08821231, 0.49326773, 0.16798021, 0.1149552 ,\n",
       "       0.15976573, 0.0778772 , 0.38857618, 0.0347604 , 0.14858592])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(10, x, y, z, model_fit=lassoreg_polynomial, lambdan=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad681ae3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f095942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
